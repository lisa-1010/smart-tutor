{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sketchbook to experiment with RNN models to model the dynamics. Once tested, the code in this notebook will be incorporated into functions/classes/ python modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics Model\n",
    "Models the dynamics of the system p(next observation | history of observations, action)\n",
    "\n",
    "History of observations consist of exercises a student has done and whether the student solved each of them\n",
    "\n",
    "Action is the next exercise chosen \n",
    "\n",
    "Next observation is whether the student gets the chosen exercise correct\n",
    "\n",
    "\n",
    "We want to use an RNN to model the dynamics.\n",
    "Input data represents history of observations, of shape (n_students, n_timesteps, observation_vec_size)\n",
    "\n",
    "Output represents the probability of getting next exercise correctly, of shape (n_students, n_timesteps, n_exercises) \n",
    "\n",
    "So at each timestep, we make a prediction for all actions. \n",
    "\n",
    "For each action, the output vector specifies the predicted probability of the student getting the chosen exercise correctly.\n",
    "\n",
    "The target output only contains binary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lisa1010/tf_venv/bin/python\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print sys.executable\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sonnet as snt\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dataset_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "Data is a list of length num_students. \n",
    "len(data) = # students\n",
    "Each element in data corresponds to a single student, and is a list of length max sequence length. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = dataset_utils.load_data(filename=\"../synthetic_data/toy.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of students: 5\n"
     ]
    }
   ],
   "source": [
    "print (\"number of students: {}\".format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence length for each student: 50\n"
     ]
    }
   ],
   "source": [
    "print (\"sequence length for each student: {}\".format(len(data[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "student_sample = data[0]\n",
    "t = 25\n",
    "student_at_t = student_sample[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exer, perf, knowl = student_at_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise Concept: 5 \n",
      "Performance (1 means solved exercise): 1 \n",
      "Knowledge (which concepts student knows): [ 1.  1.  1.  1.  1.  1.  1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print (\"Exercise Concept: {} \\nPerformance (1 means solved exercise): {} \\nKnowledge (which concepts student knows): {}\".format(np.argmax(exer), perf, knowl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input and target data for one student at timestep t\n",
    "## Constructing input data (history of observations): combining exercise concepts with performance:\n",
    "\n",
    "input data shape (n_students, n_timesteps, observation_vec_size)\n",
    "1. Concatenate\n",
    "2. multiply concept vector by -1 if student did not get it right.\n",
    "3. Construct vector of length 2*n_concepts, where orginal concept vector is copied into first half if student got it correct, or second half if student got it incorrect. (following same approach as in Piech et al. DKT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# concatenate\n",
    "observ_concat = np.append(exer, perf)\n",
    "print observ_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# flip\n",
    "observ_flip = exer * (2*perf-1)\n",
    "print observ_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extend\n",
    "observ_extend = np.zeros(2*len(exer))\n",
    "if perf == 1:\n",
    "    observ_extend[:len(exer)] = exer\n",
    "else:\n",
    "    observ_extend[len(exer):] = exer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print observ_extend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing targets\n",
    "Note that the output of the RNN at timestep t is a vector of length n_exercises, each element representing the probability that a student will get that exercise correctly. \n",
    "Targets shape: (n_students, n_timesteps, n_exercises) \n",
    "\n",
    "For training, we calculate the loss only over the outputs corresponding to the observed exercises, so the ones the student actually did.\n",
    "\n",
    "Therefore, we need an outputmask, to mask out all other exercises the student did not do. the output mask is a one hot vector for each timestep,  corresponding to the exercise the student did at t. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_ex, next_perf, next_knowl = student_sample[t+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print next_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# actions corresponds to number of exercises. Right now, each exercise practices one concept. \n",
    "\n",
    "So \\# exercises = \\# concepts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_concepts = 10\n",
    "n_exercises = n_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_vec  = np.zeros(n_exercises)\n",
    "output_mask = np.zeros(n_exercises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exercise_ix = np.argmax(next_ex) # for current data set, this works. In the future, if exercise doesn't correspond to just a single concept, we would have to use exercise IDs.\n",
    "output_mask[exercise_ix] = 1\n",
    "target_vec[exercise_ix] = next_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print output_mask\n",
    "print target_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct input and targets for entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_students = len(data)\n",
    "n_timesteps = len(data[0])\n",
    "exer = data[0][0][0]\n",
    "n_concepts = len(exer)\n",
    "n_inputdim = 2 * n_concepts\n",
    "n_exercises = n_concepts\n",
    "n_outputdim = n_exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print n_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print n_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print n_inputdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_data_ = np.zeros((n_students, n_timesteps, n_inputdim))\n",
    "output_mask_ = np.zeros((n_students, n_timesteps, n_outputdim))\n",
    "target_data_ = np.zeros((n_students, n_timesteps, n_outputdim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 50, 20)\n"
     ]
    }
   ],
   "source": [
    "print input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(n_students):\n",
    "    for t in xrange(n_timesteps-1):\n",
    "        cur_sample = data[i][t]\n",
    "        next_sample = data[i][t+1]\n",
    "        exer, perf, knowl = cur_sample\n",
    "        next_exer, next_perf, next_knowl = next_sample\n",
    "        next_exer_ix = np.argmax(next_exer)\n",
    "        \n",
    "        observ = np.zeros(2*len(exer))\n",
    "        if perf == 1:\n",
    "            observ[:len(exer)] = exer\n",
    "        else:\n",
    "            observ[len(exer):] = exer\n",
    "            \n",
    "        input_data_[i,t,:] = observ[:]\n",
    "        \n",
    "        output_mask_[i,t,next_exer_ix] = 1\n",
    "        target_data_[i,t,next_exer_ix] = next_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE: consolidated above code into dataset_utils.py. \n",
    "\n",
    "Loading and preprocessing data can now be done with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = dataset_utils.load_data(filename=\"../synthetic_data/toy.pickle\")\n",
    "input_data_, output_mask_, target_data_ = dataset_utils.preprocess_data_for_rnn(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpu_options {\n",
       "}\n",
       "allow_soft_placement: true"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflearn.init_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: 8JL72Y\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/lstm_1.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/lstm_2.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "---------------------------------\n",
      "Training samples: 4\n",
      "Validation samples: 1\n",
      "--\n",
      "Training Step: 1  | time: 1.863s\n",
      "| Adam | epoch: 001 | loss: 0.00000 | val_loss: 0.04663 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.04059\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 002 | loss: 0.04059 | val_loss: 0.04580 -- iter: 4/4\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.04370\u001b[0m\u001b[0m | time: 1.057s\n",
      "| Adam | epoch: 003 | loss: 0.04370 | val_loss: 0.04496 -- iter: 4/4\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.04368\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 004 | loss: 0.04368 | val_loss: 0.04408 -- iter: 4/4\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.04318\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 005 | loss: 0.04318 | val_loss: 0.04316 -- iter: 4/4\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.04263\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 006 | loss: 0.04263 | val_loss: 0.04218 -- iter: 4/4\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.04193\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 007 | loss: 0.04193 | val_loss: 0.04113 -- iter: 4/4\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.04121\u001b[0m\u001b[0m | time: 0.050s\n",
      "| Adam | epoch: 008 | loss: 0.04121 | val_loss: 0.03999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.04044\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 009 | loss: 0.04044 | val_loss: 0.03874 -- iter: 4/4\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.03963\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 010 | loss: 0.03963 | val_loss: 0.03736 -- iter: 4/4\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 64\n",
    "\n",
    "graph_to_use = tf.Graph()\n",
    "with graph_to_use.as_default():\n",
    "    net = tflearn.input_data([None, n_timesteps, n_inputdim],dtype=tf.float32, name='input_data')\n",
    "    output_mask = tflearn.input_data([None, n_timesteps, n_outputdim], dtype=tf.float32, name='output_mask')\n",
    "    net = tflearn.lstm(net, n_hidden, return_seq=True, name=\"lstm_1\")\n",
    "    net = tflearn.lstm(net, n_outputdim, return_seq=True, name=\"lstm_2\")\n",
    "    net = tf.stack(net, axis=1)\n",
    "    preds = net\n",
    "    net = net * output_mask\n",
    "    net = tflearn.regression(net, optimizer='adam', learning_rate=0.001,\n",
    "                             loss='mean_square')\n",
    "    model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "    model.fit([ input_data_, output_mask_], target_data_, validation_set=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'output_mask:0' shape=(?, 50, 10) dtype=int32>,\n",
       " <tf.Tensor 'InputData/X:0' shape=(?, 50, 20) dtype=float32>,\n",
       " <tf.Tensor 'output_mask_1:0' shape=(?, 50, 10) dtype=int32>,\n",
       " <tf.Tensor 'InputData_1/X:0' shape=(?, 50, 20) dtype=float32>,\n",
       " <tf.Tensor 'output_mask_2:0' shape=(?, 50, 10) dtype=int32>,\n",
       " <tf.Tensor 'InputData_2/X:0' shape=(?, 50, 20) dtype=float32>,\n",
       " <tf.Tensor 'output_mask_3:0' shape=(?, 50, 10) dtype=float32>,\n",
       " <tf.Tensor 'InputData_3/X:0' shape=(?, 50, 20) dtype=float32>,\n",
       " <tf.Tensor 'input_data:0' shape=(?, 50, 20) dtype=float32>,\n",
       " <tf.Tensor 'output_mask_4:0' shape=(?, 50, 10) dtype=float32>,\n",
       " <tf.Tensor 'input_data_1:0' shape=(?, 50, 20) dtype=float32>,\n",
       " <tf.Tensor 'output_mask_5:0' shape=(?, 50, 10) dtype=float32>,\n",
       " <tf.Tensor 'input_data_2:0' shape=(?, 50, 20) dtype=float32>,\n",
       " <tf.Tensor 'output_mask_6:0' shape=(?, 50, 10) dtype=float32>,\n",
       " <tf.Tensor 'input_data_3:0' shape=(?, 50, 20) dtype=float32>,\n",
       " <tf.Tensor 'output_mask_7:0' shape=(?, 50, 10) dtype=float32>,\n",
       " <tf.Tensor 'input_data_4:0' shape=(?, 50, 20) dtype=float32>,\n",
       " <tf.Tensor 'output_mask_8:0' shape=(?, 50, 10) dtype=float32>,\n",
       " <tf.Tensor 'output_mask_9:0' shape=(?, 50, 10) dtype=float32>,\n",
       " <tf.Tensor 'input_data_5/X:0' shape=(?, 50, 20) dtype=float32>,\n",
       " <tf.Tensor 'input_data_6/X:0' shape=(?, 50, 20) dtype=float32>,\n",
       " <tf.Tensor 'output_mask_10/X:0' shape=(?, 50, 10) dtype=float32>,\n",
       " <tf.Tensor 'output_mask_9:0' shape=(?, 50, 10) dtype=float32>,\n",
       " <tf.Tensor 'input_data_7/X:0' shape=(?, 50, 20) dtype=float32>,\n",
       " <tf.Tensor 'output_mask_11/X:0' shape=(?, 50, 10) dtype=float32>,\n",
       " <tf.Tensor 'output_mask_9:0' shape=(?, 50, 10) dtype=float32>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.INPUTS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 tf_venv shared",
   "language": "python",
   "name": "tf_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
