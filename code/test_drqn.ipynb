{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import drqn\n",
    "import student as st\n",
    "\n",
    "import data_generator as dg\n",
    "import concept_dependency_graph as cdg\n",
    "from experience_buffer import ExperienceBuffer\n",
    "import dataset_utils as d_utils\n",
    "import utils\n",
    "import models_dict_utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data for DRQN\n",
    "We take the data from data generator and save them into traces of (s,a,r,sp) tuples.\n",
    "\n",
    "Each trajectory corresponds to a trace.\n",
    "\n",
    "If trajectory has length n, then trace will have length n-1. (since we need the next state sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = d_utils.load_data(filename=\"../synthetic_data/test-n10000-l3-random.pickle\")\n",
    "dqn_data = d_utils.preprocess_data_for_dqn(data, reward_model=\"dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]), array([ 1.,  0.,  0.,  0.,  0.]), 0.20000000000000001, array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])], [array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  1.]), 0.20000000000000001, array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.])]]\n"
     ]
    }
   ],
   "source": [
    "# Single Trace\n",
    "print (dqn_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "[ 1.  0.  0.  0.  0.]\n",
      "0.2\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# First tuple in a trace\n",
    "s,a,r,sp = dqn_data[0][0]\n",
    "print (s)\n",
    "print (a)\n",
    "print (r)\n",
    "print (sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "0.2\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Last tuple\n",
    "s,a,r,sp = dqn_data[0][-1]\n",
    "print (s)\n",
    "print (a)\n",
    "print (r)\n",
    "print (sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dqn_data_train, dqn_data_test = train_test_split(dqn_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DRQN model and training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_id = \"test_model_drqn\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the model object\n",
    "model = drqn.DRQNModel(model_id, timesteps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize trainer object inside the model\n",
    "model.init_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating training and validation data\n",
    "train_buffer = ExperienceBuffer()\n",
    "train_buffer.buffer = dqn_data_train\n",
    "train_buffer.buffer_sz = len(train_buffer.buffer)\n",
    "\n",
    "val_buffer = ExperienceBuffer()\n",
    "val_buffer.buffer = dqn_data_test\n",
    "val_buffer.buffer_sz = len(val_buffer.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 39249  | total loss: \u001b[1m\u001b[32m0.08859\u001b[0m\u001b[0m | time: 2.143s\n",
      "| Optimizer | epoch: 007 | loss: 0.08859 -- iter: 7936/8000\n",
      "Training Step: 39250  | total loss: \u001b[1m\u001b[32m0.08909\u001b[0m\u001b[0m | time: 3.175s\n",
      "| Optimizer | epoch: 007 | loss: 0.08909 | val_loss: 0.08739 -- iter: 8000/8000\n",
      "--\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/lstm_2.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/lstm_1.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n"
     ]
    }
   ],
   "source": [
    "# train the model (uses the previously initialized trainer object)\n",
    "date_time_string = datetime.datetime.now().strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "run_id = \"{}\".format(date_time_string)\n",
    "model.train(train_buffer, val_buffer, n_epoch=2,\n",
    "              run_id=run_id, load_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# init evaluator of the model\n",
    "model.init_evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create inputs (states / observations so far) to use for predictions\n",
    "from drqn import stack_batch\n",
    "train_batch = train_buffer.sample_in_order(4)\n",
    "\n",
    "# make sure that batches are over multiple timesteps, should be of shape (batch_sz, n_timesteps, ?)\n",
    "s_batch_train = stack_batch(train_batch[:, :, 0])  # current states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use model to predict next action\n",
    "actions, q_vals = model.predict(s_batch_train, last_timestep_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30861092,  0.30838254,  0.30854946,  0.30801374,  0.30847904],\n",
       "       [ 0.31383398,  0.31383744,  0.31381938,  0.31383258,  0.31286329],\n",
       "       [ 0.44942483,  0.44977263,  0.44959086,  0.4496491 ,  0.44962877],\n",
       "       [ 0.32500198,  0.32455364,  0.32502168,  0.32404408,  0.32474533]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if we want to predict on data with different number of timesteps then we trained on, \n",
    "# create a new model but using the same checkpoint\n",
    "\n",
    "eval_model = drqn.DRQNModel(model_id, timesteps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_model.init_evaluator()\n",
    "# now the internal RNN will be unrolled over 10 timesteps. \n",
    "# You can still pass in inputs that have fewer than 10, in which case remaining timesteps will be padded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 1, 2]),\n",
       " array([[ 0.30861092,  0.30838254,  0.30854946,  0.30801374,  0.30847904],\n",
       "        [ 0.31383398,  0.31383744,  0.31381938,  0.31383258,  0.31286329],\n",
       "        [ 0.44942483,  0.44977263,  0.44959086,  0.4496491 ,  0.44962877],\n",
       "        [ 0.32500198,  0.32455364,  0.32502168,  0.32404408,  0.32474533]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model.predict(s_batch_train, last_timestep_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from drqn_tests import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_trajectories = 10\n",
    "n_concepts = 5\n",
    "horizon = 6\n",
    "model_id = \"test_model_drqn\"\n",
    "from simple_mdp import create_custom_dependency\n",
    "dgraph = create_custom_dependency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model = drqn.DRQNModel(model_id=model_id, timesteps=horizon)\n",
    "test_model.init_evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learn_prob = 0.15\n",
    "student = st.Student(n=n_concepts, p_trans_satisfied=learn_prob, p_trans_not_satisfied=0.0, p_get_ex_correct_if_concepts_learned=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR [ 1.  0.  0.  0.  0.] executed non-optimal action 0\n",
      "ERROR [ 1.  0.  0.  0.  0.] executed non-optimal action 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = test_drqn_single(dgraph, student, horizon, test_model, DEBUG=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj i 0\n",
      "traj i 1\n",
      "traj i 2\n",
      "traj i 3\n",
      "traj i 4\n",
      "traj i 5\n",
      "traj i 6\n",
      "traj i 7\n",
      "traj i 8\n",
      "traj i 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29999999999999999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_drqn_chunk(n_trajectories, dgraph, student, model_id, horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Test Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: test_model_drqn\n",
      "horizon: 6\n",
      "traj i 0\n",
      "traj i 1\n",
      "traj i 2\n",
      "traj i 3\n",
      "traj i 4\n",
      "traj i 5\n",
      "traj i 6\n",
      "traj i 7\n",
      "traj i 8\n",
      "traj i 9\n",
      "Generating data for 1000 students with behavior policy expert and sequence length 6.\n",
      "Average posttest true: 0.385\n",
      "Average posttest drqn: 0.22\n"
     ]
    }
   ],
   "source": [
    "test_drqn(model_id=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test2-n100000-l7-random.pickle\n"
     ]
    }
   ],
   "source": [
    "n_concepts = 4\n",
    "use_student2 = True\n",
    "student2_str = '2' if use_student2 else ''\n",
    "learn_prob = 0.15\n",
    "lp_str = '-lp{}'.format(int(learn_prob*100)) if not use_student2 else ''\n",
    "n_students = 100000\n",
    "seqlen = 7\n",
    "filter_mastery = False\n",
    "filter_str = '' if not filter_mastery else '-filtered'\n",
    "policy = 'random'\n",
    "filename = 'test{}-n{}-l{}{}-{}{}.pickle'.format(student2_str, n_students, seqlen,\n",
    "                                                    lp_str, policy, filter_str)\n",
    "#concept_tree = sm.create_custom_dependency()\n",
    "concept_tree = cdg.ConceptDependencyGraph()\n",
    "concept_tree.init_default_tree(n_concepts)\n",
    "if not use_student2:\n",
    "    test_student = st.Student(n=n_concepts,p_trans_satisfied=learn_prob, p_trans_not_satisfied=0.0, p_get_ex_correct_if_concepts_learned=1.0)\n",
    "else:\n",
    "    test_student = st.Student2(n_concepts)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing synthetic data sets...\n",
      "Generating data for 100000 students with behavior policy random and sequence length 7.\n",
      "Data generation completed. \n"
     ]
    }
   ],
   "source": [
    "print (\"Initializing synthetic data sets...\")\n",
    "dg.generate_data(concept_tree, student=test_student, n_students=n_students, filter_mastery=filter_mastery, seqlen=seqlen, policy=policy, filename=\"{}{}\".format(dg.SYN_DATA_DIR, filename))\n",
    "print (\"Data generation completed. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = d_utils.load_data(filename=\"../synthetic_data/{}\".format(filename))\n",
    "dqn_data = d_utils.preprocess_data_for_dqn(data, reward_model=\"dense\")\n",
    "dqn_data_train, dqn_data_test = train_test_split(dqn_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating training and validation data\n",
    "train_buffer = ExperienceBuffer()\n",
    "train_buffer.buffer = dqn_data_train\n",
    "train_buffer.buffer_sz = len(train_buffer.buffer)\n",
    "\n",
    "val_buffer = ExperienceBuffer()\n",
    "val_buffer.buffer = dqn_data_test\n",
    "val_buffer.buffer_sz = len(val_buffer.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model test2_model_drqn_mid\n"
     ]
    }
   ],
   "source": [
    "model_id = \"test2_model_drqn_mid\"\n",
    "model = drqn.DRQNModel(model_id, timesteps=seqlen-1)\n",
    "model.init_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6863  | total loss: \u001b[1m\u001b[32m0.03597\u001b[0m\u001b[0m | time: 15.444s\n",
      "\u001b[2K\r",
      "| Optimizer | epoch: 006 | loss: 0.03597 -- iter: 39232/80000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-7d5db90633ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrun_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_time_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model.train(train_buffer, val_buffer, n_epoch=32,\n\u001b[0;32m----> 5\u001b[0;31m               run_id=run_id, load_checkpoint=True)\n\u001b[0m",
      "\u001b[0;32m/Users/lisa1010/dev/smart-tutor/code/drqn.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_buffer, val_buffer, n_epoch, run_id, load_checkpoint, load_ckpt_path)\u001b[0m\n\u001b[1;32m    156\u001b[0m         self.trainer.fit({q_inputs: s_batch_train, a: a_batch_train, r: r_batch_train, target_inputs: sp_batch_train},\n\u001b[1;32m    157\u001b[0m                     \u001b[0mval_feed_dicts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mq_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms_batch_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma_batch_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr_batch_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msp_batch_val\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                     n_epoch=n_epoch, snapshot_epoch=True, run_id=run_id)\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lisa1010/tf_venv/lib/python2.7/site-packages/tflearn/helpers/trainer.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001b[0m\n\u001b[1;32m    331\u001b[0m                                                        \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0msnapshot_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                                                        \u001b[0msnapshot_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                                                        show_metric)\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                             \u001b[0;31m# Update training state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lisa1010/tf_venv/lib/python2.7/site-packages/tflearn/helpers/trainer.pyc\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, training_step, snapshot_epoch, snapshot_step, show_metric)\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0mtflearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         _, train_summ_str = self.session.run([self.train, self.summ_op],\n\u001b[0;32m--> 774\u001b[0;31m                                              feed_batch)\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;31m# Retrieve loss value from summary string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lisa1010/tf_venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lisa1010/tf_venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lisa1010/tf_venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/lisa1010/tf_venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lisa1010/tf_venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model (uses the previously initialized trainer object)\n",
    "date_time_string = datetime.datetime.now().strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "run_id = \"{}\".format(date_time_string)\n",
    "model.train(train_buffer, val_buffer, n_epoch=32,\n",
    "              run_id=run_id, load_checkpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Model in \"real world\" and calculate post test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: test2_model_drqn_mid\n",
      "horizon: 6\n",
      "Loaded model test2_model_drqn_mid\n",
      "Loaded model test2_model_drqn_mid\n",
      "Loaded model test2_model_drqn_mid\n",
      "Loaded model test2_model_drqn_mid\n",
      "Loaded model test2_model_drqn_mid\n",
      "Loaded model test2_model_drqn_mid\n",
      "Loaded model test2_model_drqn_mid\n",
      "Loaded model test2_model_drqn_mid\n"
     ]
    }
   ],
   "source": [
    "test_drqn(model_id=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 tf_venv shared",
   "language": "python",
   "name": "tf_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
